{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\.conda\\envs\\Noh_ver2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"kykim/bert-kor-base\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_emotion(text):\n",
    "    # 텍스트 토큰화 및 패딩\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    # 예측 수행\n",
    "    with torch.no_grad():\n",
    "        prediction = model(**tokens)\n",
    "\n",
    "\t\t# 예측 결과를 바탕으로 감정 출력\n",
    "    prediction = F.softmax(prediction.logits, dim=1)\n",
    "    output = prediction.argmax(dim=1).item()\n",
    "    labels = [\"부정적\", \"긍정적\"]\n",
    "    print(f'[{labels[output]}]\\\\n')\n",
    "    return labels[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           text\n",
      "0                           NaN\n",
      "1                    세상이 말세긴 한듯\n",
      "2        군발언 영상 보고 어우야 했는데해명됬나요\n",
      "3  언젠가는 이세돌이 모두에게 인정받는 날이 올 것이다\n",
      "4                      우왁굳의 승리네\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# CSV 파일 로드\n",
    "file_path = 'data_ver4.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[부정적]\\n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'부정적'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_emotion(df.iloc[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>세상이 말세긴 한듯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>군발언 영상 보고 어우야 했는데해명됬나요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>언젠가는 이세돌이 모두에게 인정받는 날이 올 것이다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>우왁굳의 승리네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>할머니집 컴퓨터로 챗 들어간 느낌이네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>스텔라이브 하위호환</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>바둑기사 라는 말만 안나왔으면 좋겠다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>나도 이세페 가고싶은데 다른 나라에 살아서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>편집자 주폭도 확인</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>바둑기사 이세돌님 자기 이름 오염돼서 상당히 빡치시겠네 네이버나 구글에 검색할 때도...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "1                                           세상이 말세긴 한듯\n",
       "2                               군발언 영상 보고 어우야 했는데해명됬나요\n",
       "3                         언젠가는 이세돌이 모두에게 인정받는 날이 올 것이다\n",
       "4                                             우왁굳의 승리네\n",
       "5                                 할머니집 컴퓨터로 챗 들어간 느낌이네\n",
       "..                                                 ...\n",
       "386                                         스텔라이브 하위호환\n",
       "387                               바둑기사 라는 말만 안나왔으면 좋겠다\n",
       "388                            나도 이세페 가고싶은데 다른 나라에 살아서\n",
       "389                                         편집자 주폭도 확인\n",
       "390  바둑기사 이세돌님 자기 이름 오염돼서 상당히 빡치시겠네 네이버나 구글에 검색할 때도...\n",
       "\n",
       "[381 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_df = df.dropna(axis=0)\n",
    "fixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "[부정적]\\n\n",
      "[긍정적]\\n\n",
      "[부정적]\\n\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for index, row in fixed_df.iterrows():\n",
    "    try:\n",
    "        results.append(classify_emotion(fixed_df.iloc[index, 0]))\n",
    "    except :\n",
    "        print(\"Error\")\n",
    "        results.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_3112\\35164244.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fixed_df['state'] = results\n"
     ]
    }
   ],
   "source": [
    "fixed_df['state'] = results\n",
    "fixed_df\n",
    "\n",
    "fixed_df.to_csv('train_data_ver4.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부정적인 텍스트가 호출된 횟수: 317\n",
      "긍정적인 텍스트가 호출된 횟수: 54\n"
     ]
    }
   ],
   "source": [
    "# 'text' 열에서 '부정적' 텍스트가 포함된 행 찾기\n",
    "negative_texts = fixed_df[fixed_df['state'].str.contains('부정적')]\n",
    "positive_texts = fixed_df[fixed_df['state'].str.contains('긍정적')]\n",
    "# 부정적인 텍스트가 포함된 행의 개수 계산\n",
    "count_negative_texts = len(negative_texts)\n",
    "count_positive_texts = len(positive_texts)\n",
    "print(\"부정적인 텍스트가 호출된 횟수:\", count_negative_texts)\n",
    "print(\"긍정적인 텍스트가 호출된 횟수:\", count_positive_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Noh_ver2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
